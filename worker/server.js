const express = require('express');
const cors = require('cors');
const Anthropic = require('@anthropic-ai/sdk');

const app = express();
app.use(cors());
app.use(express.json());

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// ============ AI MODELLERÄ° ============

async function callGPT(message, task = 'araÅŸtÄ±r') {
  try {
    const res = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          { role: 'system', content: `Sen araÅŸtÄ±rma uzmanÄ±sÄ±n. GÃ¶revi ${task}. DetaylÄ± araÅŸtÄ±r, kaynak belirt. TÃ¼rkÃ§e cevap ver.` },
          { role: 'user', content: message }
        ],
        max_tokens: 4096
      })
    });
    const data = await res.json();
    return data.choices?.[0]?.message?.content || 'GPT yanÄ±t veremedi.';
  } catch (e) {
    return 'GPT HatasÄ±: ' + e.message;
  }
}

async function callGemini(message, task = 'analiz et') {
  try {
    const res = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${process.env.GOOGLE_API_KEY}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ contents: [{ parts: [{ text: `GÃ¶rev: ${task}\n\n${message}` }] }] })
      }
    );
    const data = await res.json();
    return data.candidates?.[0]?.content?.parts?.[0]?.text || 'Gemini yanÄ±t veremedi.';
  } catch (e) {
    return 'Gemini HatasÄ±: ' + e.message;
  }
}

async function callTogether(message, task = 'deÄŸerlendir') {
  try {
    const res = await fetch('https://api.together.xyz/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.TOGETHER_API_KEY}`
      },
      body: JSON.stringify({
        model: 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',
        messages: [
          { role: 'system', content: `GÃ¶revin: ${task}. FarklÄ± bir bakÄ±ÅŸ aÃ§Ä±sÄ± sun. TÃ¼rkÃ§e cevap ver.` },
          { role: 'user', content: message }
        ],
        max_tokens: 4096
      })
    });
    const data = await res.json();
    return data.choices?.[0]?.message?.content || 'Together yanÄ±t veremedi.';
  } catch (e) {
    return 'Together HatasÄ±: ' + e.message;
  }
}

async function callV0(message) {
  try {
    const res = await fetch('https://api.v0.dev/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.V0_API_KEY}`
      },
      body: JSON.stringify({
        model: 'v0-1.0-md',
        messages: [{ role: 'user', content: message }],
        max_tokens: 4096
      })
    });
    const data = await res.json();
    return data.choices?.[0]?.message?.content || 'V0 yanÄ±t veremedi.';
  } catch (e) {
    return 'V0 HatasÄ±: ' + e.message;
  }
}

async function callCursor(task) {
  try {
    const res = await fetch('https://api.cursor.com/v0/agents', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': 'Basic ' + Buffer.from(process.env.CURSOR_API_KEY + ':').toString('base64')
      },
      body: JSON.stringify({
        prompt: { text: task },
        source: { repository: 'https://github.com/serdincaltay-ai/yisa-s-app', ref: 'main' },
        target: { autoCreatePr: true }
      })
    });
    const data = await res.json();
    if (data.id) return { success: true, id: data.id, url: `https://cursor.com/agents?id=${data.id}` };
    return { success: false, error: JSON.stringify(data) };
  } catch (e) {
    return { success: false, error: e.message };
  }
}

// ============ ARAÃ‡LAR ============

async function githubListRepos() {
  const res = await fetch('https://api.github.com/user/repos?per_page=20&sort=updated', {
    headers: { 'Authorization': `token ${process.env.GITHUB_TOKEN_FINEGRAINED || process.env.GITHUB_TOKEN}` }
  });
  const repos = await res.json();
  return Array.isArray(repos) ? repos.map(r => r.name).join(', ') : 'AlÄ±namadÄ±';
}

async function vercelListProjects() {
  const res = await fetch('https://api.vercel.com/v9/projects', {
    headers: { 'Authorization': `Bearer ${process.env.VERCEL_TOKEN}` }
  });
  const data = await res.json();
  return data.projects ? data.projects.map(p => p.name).join(', ') : 'AlÄ±namadÄ±';
}

async function supabaseQuery(table, action = 'select') {
  const res = await fetch(`${process.env.SUPABASE_URL}/rest/v1/${table}?limit=10`, {
    headers: {
      'Authorization': `Bearer ${process.env.SUPABASE_SERVICE_ROLE_KEY}`,
      'apikey': process.env.SUPABASE_SERVICE_ROLE_KEY
    }
  });
  return await res.json();
}

// ============ MASTER ORCHESTRATOR ============

const MASTER_PROMPT = `Sen YÄ°SA-S Ana Asistan'sÄ±n. Patron SerdinÃ§ Altay'Ä±n kiÅŸisel AI asistanÄ±sÄ±n.

GÃ–REV: Patron'un isteklerini analiz et, doÄŸru AI'larÄ± ve araÃ§larÄ± seÃ§, iÅŸi yaptÄ±r, sonucu sun.

MEVCUT AI'LAR:
- GPT: AraÅŸtÄ±rma, bilgi toplama
- Gemini: Grafik, gÃ¶rsel analiz, tasarÄ±m deÄŸerlendirme
- Together: FarklÄ± bakÄ±ÅŸ aÃ§Ä±sÄ±, alternatif deÄŸerlendirme
- Claude (sen): DÃ¼zenleme, birleÅŸtirme, final karar
- V0: UI/Component Ã¼retimi
- Cursor: Kod yazma, hata dÃ¼zeltme, PR oluÅŸturma

ARAÃ‡LAR:
- GitHub: Repo yÃ¶netimi
- Vercel: Deployment
- Supabase: VeritabanÄ±
- Railway: Backend

ROBOTLAR (Supabase'de tanÄ±mlÄ±):
- CEO, COO, CTO, CFO, CMO, CPO, CSO, CCO, CHRO
- CISO (Siber GÃ¼venlik)
- Veri Robotu
- YÄ°SA-S Self

Ã‡ALIÅžMA PRENSÄ°BÄ°:
1. Ä°steÄŸi analiz et
2. 2 farklÄ± AI'dan gÃ¶rÃ¼ÅŸ al (hangisi uygunsa)
3. SonuÃ§larÄ± birleÅŸtir ve dÃ¼zenle
4. Ãœretim iÅŸiyse V0'a gÃ¶nder
5. Kod iÅŸiyse Cursor'a gÃ¶nder
6. Komut iÅŸiyse direkt Ã§alÄ±ÅŸtÄ±r

CEVAP: JSON formatÄ±nda dÃ¶ndÃ¼r:
{
  "plan": "Ne yapÄ±lacak kÄ±sa aÃ§Ä±klama",
  "ai_tasks": [{"ai": "gpt", "task": "..."}, {"ai": "gemini", "task": "..."}],
  "tools": ["github", "v0"],
  "final_action": "v0|cursor|direct|report"
}`;

async function masterOrchestrate(userMessage) {
  let report = '';
  
  try {
    // 1. Plan yap
    const planResult = await anthropic.messages.create({
      model: 'claude-sonnet-4-20250514',
      max_tokens: 1024,
      system: MASTER_PROMPT,
      messages: [{ role: 'user', content: userMessage }],
    });
    
    const planText = planResult.content[0].text;
    let plan;
    
    try {
      const jsonMatch = planText.match(/\{[\s\S]*\}/);
      plan = jsonMatch ? JSON.parse(jsonMatch[0]) : null;
    } catch {
      // Basit soru, direkt cevapla
      const direct = await anthropic.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 4096,
        system: 'Sen YÄ°SA-S AsistanÄ±sÄ±n. Patron SerdinÃ§ Altay\'a yardÄ±m et. TÃ¼rkÃ§e, profesyonel, kÄ±sa cevap ver.',
        messages: [{ role: 'user', content: userMessage }],
      });
      return direct.content[0].text;
    }

    if (!plan) {
      const direct = await anthropic.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 4096,
        system: 'Sen YÄ°SA-S AsistanÄ±sÄ±n. Patron SerdinÃ§ Altay\'a yardÄ±m et. TÃ¼rkÃ§e, profesyonel, kÄ±sa cevap ver.',
        messages: [{ role: 'user', content: userMessage }],
      });
      return direct.content[0].text;
    }

    report += `ðŸŽ¯ **GÃ–REV:** ${plan.plan}\n\n`;

    // 2. AI'larÄ± Ã§alÄ±ÅŸtÄ±r
    const aiResults = {};
    
    if (plan.ai_tasks && plan.ai_tasks.length > 0) {
      report += `ðŸ¤– **AI Ã‡ALIÅžIYOR:**\n`;
      
      for (const task of plan.ai_tasks) {
        if (task.ai === 'gpt') {
          report += `ðŸ“Š GPT araÅŸtÄ±rÄ±yor...\n`;
          aiResults.gpt = await callGPT(task.task);
        } else if (task.ai === 'gemini') {
          report += `ðŸŽ¨ Gemini analiz ediyor...\n`;
          aiResults.gemini = await callGemini(task.task);
        } else if (task.ai === 'together') {
          report += `ðŸ”„ Together deÄŸerlendiriyor...\n`;
          aiResults.together = await callTogether(task.task);
        }
      }
      report += `\n`;
    }

    // 3. AraÃ§larÄ± Ã§alÄ±ÅŸtÄ±r
    if (plan.tools && plan.tools.length > 0) {
      report += `ðŸ”§ **ARAÃ‡LAR:**\n`;
      
      for (const tool of plan.tools) {
        if (tool === 'github') {
          const repos = await githubListRepos();
          report += `ðŸ“ GitHub: ${repos}\n`;
        } else if (tool === 'vercel') {
          const projects = await vercelListProjects();
          report += `ðŸš€ Vercel: ${projects}\n`;
        }
      }
      report += `\n`;
    }

    // 4. Final iÅŸlem
    if (plan.final_action === 'v0' && aiResults.gpt) {
      report += `ðŸŽ¨ **V0 ÃœRETÄ°M:**\n`;
      const v0Result = await callV0(aiResults.gpt);
      report += v0Result + '\n\n';
    } else if (plan.final_action === 'cursor') {
      report += `ðŸ’» **CURSOR:**\n`;
      const cursorResult = await callCursor(userMessage);
      if (cursorResult.success) {
        report += `âœ… Agent baÅŸlatÄ±ldÄ±: ${cursorResult.url}\n\n`;
      } else {
        report += `âŒ Hata: ${cursorResult.error}\n\n`;
      }
    }

    // 5. SonuÃ§larÄ± birleÅŸtir
    if (Object.keys(aiResults).length > 0) {
      report += `ðŸ“‹ **SONUÃ‡LAR:**\n\n`;
      
      if (aiResults.gpt) {
        report += `**GPT AraÅŸtÄ±rmasÄ±:**\n${aiResults.gpt}\n\n`;
      }
      if (aiResults.gemini) {
        report += `**Gemini Analizi:**\n${aiResults.gemini}\n\n`;
      }
      if (aiResults.together) {
        report += `**Together DeÄŸerlendirmesi:**\n${aiResults.together}\n\n`;
      }

      // Claude final dÃ¼zenleme
      const finalEdit = await anthropic.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 2048,
        system: 'Verilen AI Ã§Ä±ktÄ±larÄ±nÄ± birleÅŸtir, dÃ¼zenle, profesyonel Ã¶zet yap. TÃ¼rkÃ§e.',
        messages: [{ role: 'user', content: JSON.stringify(aiResults) }],
      });
      
      report += `âœ… **FÄ°NAL:**\n${finalEdit.content[0].text}\n`;
    }

    return report;

  } catch (e) {
    return `Hata: ${e.message}`;
  }
}

// ============ HIZLI KOMUTLAR ============

function detectQuickCommand(msg) {
  const m = msg.toLowerCase();
  if (m.includes('github repo') || m.includes('github listele')) return 'github';
  if (m.includes('vercel proje')) return 'vercel';
  if (m.includes('supabase tablo')) return 'supabase';
  if (m.includes('railway durum')) return 'railway';
  if (m.includes('sistem kur') || m.includes('robotu kur')) return 'setup';
  if (m.includes('robot listele')) return 'robots';
  return null;
}

// ============ MAIN ENDPOINT ============

app.post('/api/chat', async (req, res) => {
  try {
    const { message } = req.body;
    if (!message) return res.status(400).json({ error: 'Mesaj gerekli' });

    const cmd = detectQuickCommand(message);
    
    if (cmd === 'github') {
      const repos = await githubListRepos();
      return res.json({ message: `ðŸ“ **GitHub Repolar:**\n${repos}`, model: 'github' });
    }
    if (cmd === 'vercel') {
      const projects = await vercelListProjects();
      return res.json({ message: `ðŸš€ **Vercel Projeler:**\n${projects}`, model: 'vercel' });
    }
    if (cmd === 'railway') {
      return res.json({ message: `ðŸš‚ **Railway:** ONLINE`, model: 'railway' });
    }
    if (cmd === 'setup') {
      return res.json({ 
        message: `ðŸ”§ **SÄ°STEM KURULUMU**\n\nPatron, hangi robotu kurmak istiyorsunuz?\n\n1. CEO Robot\n2. CISO Robot (Siber GÃ¼venlik)\n3. COO Robot\n4. Veri Robotu\n5. YÄ°SA-S Self\n6. TÃ¼m C-Level Robotlar\n\nNumara veya isim yazÄ±n.`, 
        model: 'setup' 
      });
    }
    if (cmd === 'robots') {
      return res.json({ 
        message: `ðŸ¤– **ROBOT KADROSU:**\n\nðŸ‘” CEO - Strateji\nðŸ”’ CISO - GÃ¼venlik\nâš™ï¸ COO - Operasyon\nðŸ’° CFO - Finans\nðŸ’» CTO - Teknoloji\nðŸ“¢ CMO - Pazarlama\nðŸ“¦ CPO - ÃœrÃ¼n\nðŸ›¡ï¸ CSO - Strateji\nðŸ“ž CCO - MÃ¼ÅŸteri\nðŸ‘¥ CHRO - Ä°K\nðŸ“Š Veri Robotu\nðŸ”§ YÄ°SA-S Self`, 
        model: 'system' 
      });
    }

    // Master Orchestrator
    const response = await masterOrchestrate(message);
    res.json({ message: response, model: 'master' });

  } catch (error) {
    console.error('Error:', error);
    res.json({ message: 'Hata: ' + error.message, model: 'error' });
  }
});

app.get('/health', (req, res) => {
  res.json({ status: 'ok', version: '2.0-master' });
});

const PORT = process.env.PORT || 3001;
app.listen(PORT, () => console.log(`YÄ°SA-S Master running on ${PORT}`));
