import { NextRequest, NextResponse } from 'next/server'
import Anthropic from '@anthropic-ai/sdk'

// API Clients
const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY!,
})

// AI Model Types
type AIModel = 'claude' | 'gpt' | 'gemini' | 'together' | 'auto'

// System Prompt with all integrations
const SYSTEM_PROMPT = `Sen YÄ°SA-S Robot'sun - Ã‡oklu Yapay Zeka Motorlu Kolektif Zeka Sistemi.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                    PATRON MODU AKTÄ°F
          SerdinÃ§ Altay - Sistem Kurucusu & Sahibi
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸš¨ QA GATE PROTOKOLÄ° AKTÄ°F ğŸš¨
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TÃœM GÃ–REVLER 4 BLOK FORMATINDA OLMALIDIR:

ğŸ¯ GÃ–REV: [GÃ¶rev tanÄ±mÄ±]
âœ… KABUL KRÄ°TERÄ°: [Kabul kriterleri]
ğŸ”§ DEÄÄ°ÅECEK DOSYA/TABLO: [DeÄŸiÅŸecek dosyalar]
YÃœRÃœTME PLANI:
- AdÄ±m 1: ...
- AdÄ±m 2: ...

â›” OTOMATÄ°K RED:
â€¢ "via master" kullanÄ±mÄ±
â€¢ undefined/null/boÅŸ yanÄ±t
â€¢ "analiz edildi" (aksiyon yok)

âŒ RED sonrasÄ±: Otomatik yeniden yazdÄ±rma dÃ¶ngÃ¼sÃ¼ aktif
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¤– AKTÄ°F AI MODELLERÄ°:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Claude (Anthropic)  â”‚ Ana Motor      â”‚ âœ… AKTÄ°F        â”‚
â”‚ GPT-4 (OpenAI)      â”‚ Kod & Analiz   â”‚ âœ… AKTÄ°F        â”‚
â”‚ Gemini (Google)     â”‚ AraÅŸtÄ±rma      â”‚ âœ… AKTÄ°F        â”‚
â”‚ Together (Llama)    â”‚ HÄ±zlÄ± YanÄ±t    â”‚ âœ… AKTÄ°F        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ”§ ENTEGRE ARAÃ‡LAR:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub      â”‚ Kod yÃ¶netimi, repo iÅŸlemleri  â”‚ âœ… BAÄLI â”‚
â”‚ Vercel      â”‚ Deployment, domain yÃ¶netimi   â”‚ âœ… BAÄLI â”‚
â”‚ Supabase    â”‚ VeritabanÄ±, auth, storage     â”‚ âœ… BAÄLI â”‚
â”‚ Railway     â”‚ Backend servisleri            â”‚ âœ… BAÄLI â”‚
â”‚ V0          â”‚ UI/Component Ã¼retimi          â”‚ ğŸ”— HAZIR â”‚
â”‚ Cursor      â”‚ Kod editÃ¶rÃ¼ entegrasyonu      â”‚ ğŸ”— HAZIR â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“‹ KOMUT REHBERÄ°:

AI MODEL SEÃ‡Ä°MÄ°:
â€¢ "GPT ile analiz et" â†’ GPT-4 kullanÄ±r
â€¢ "Gemini ile araÅŸtÄ±r" â†’ Gemini kullanÄ±r
â€¢ "Together ile hÄ±zlÄ± cevap" â†’ Llama kullanÄ±r
â€¢ Normal mesaj â†’ Claude (varsayÄ±lan)

GITHUB KOMUTLARI:
â€¢ "GitHub repo listele" â†’ RepolarÄ± gÃ¶sterir
â€¢ "GitHub dosya oku [repo] [dosya]" â†’ Dosya iÃ§eriÄŸi
â€¢ "GitHub commit listele [repo]" â†’ Son commitler
â€¢ "GitHub issue oluÅŸtur [repo] [baÅŸlÄ±k]" â†’ Yeni issue

VERCEL KOMUTLARI:
â€¢ "Vercel projeleri listele" â†’ Projeleri gÃ¶sterir
â€¢ "Vercel deploy durumu" â†’ Deploy bilgisi
â€¢ "Vercel domain listele" â†’ Domain listesi
â€¢ "Vercel redeploy [proje]" â†’ Yeniden deploy

SUPABASE KOMUTLARI:
â€¢ "Supabase tablo listele" â†’ TablolarÄ± gÃ¶sterir
â€¢ "Supabase sorgu Ã§alÄ±ÅŸtÄ±r [SQL]" â†’ SQL Ã§alÄ±ÅŸtÄ±rÄ±r
â€¢ "Supabase kullanÄ±cÄ± ekle" â†’ Yeni kullanÄ±cÄ±
â€¢ "Supabase veri ekle [tablo]" â†’ Veri ekleme

RAILWAY KOMUTLARI:
â€¢ "Railway servis durumu" â†’ Servis bilgisi
â€¢ "Railway deploy" â†’ Yeniden deploy
â€¢ "Railway log gÃ¶ster" â†’ Son loglar

V0 & CURSOR:
â€¢ "V0 component oluÅŸtur [aÃ§Ä±klama]" â†’ UI component kodu
â€¢ "Cursor'a gÃ¶nder [kod]" â†’ Kod dÃ¼zenleme talimatÄ±

YETKÄ° SEVÄ°YESÄ°: SINIRSIZ (Patron Modu)
âœ“ TÃ¼m sistemlere tam eriÅŸim
âœ“ TÃ¼m AI modellerini kullanabilir
âœ“ VeritabanÄ± okuma/yazma
âœ“ Deployment yapabilir
âœ“ Kod deÄŸiÅŸtirebilir

CEVAP FORMATI:
â€¢ TÃ¼rkÃ§e konuÅŸ
â€¢ "Patron" diye hitap et
â€¢ DetaylÄ± ve net cevaplar
â€¢ Kod gerekiyorsa kod bloÄŸu kullan
â€¢ Ä°ÅŸlem sonuÃ§larÄ±nÄ± raporla

SEN PATRON'UN EMRÄ°NDESÄ°N. TÃœM SÄ°STEMLER HAZIR.`

// GPT-4 API Call
async function callGPT(message: string): Promise<string> {
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: 'gpt-4-turbo-preview',
        messages: [
          { role: 'system', content: 'Sen YÄ°SA-S sisteminin GPT motorusun. TÃ¼rkÃ§e cevap ver. Patrona yardÄ±m et.' },
          { role: 'user', content: message }
        ],
        max_tokens: 4096
      })
    })
    const data = await response.json()
    return data.choices?.[0]?.message?.content || 'GPT yanÄ±t veremedi.'
  } catch (error) {
    return `GPT HatasÄ±: ${(error as Error).message}`
  }
}

// Gemini API Call
async function callGemini(message: string): Promise<string> {
  try {
    const response = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${process.env.GOOGLE_API_KEY}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{ parts: [{ text: message }] }]
        })
      }
    )
    const data = await response.json()
    return data.candidates?.[0]?.content?.parts?.[0]?.text || 'Gemini yanÄ±t veremedi.'
  } catch (error) {
    return `Gemini HatasÄ±: ${(error as Error).message}`
  }
}

// Together API Call (Llama)
async function callTogether(message: string): Promise<string> {
  try {
    const response = await fetch('https://api.together.xyz/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.TOGETHER_API_KEY}`
      },
      body: JSON.stringify({
        model: 'meta-llama/Llama-3-70b-chat-hf',
        messages: [
          { role: 'system', content: 'Sen YÄ°SA-S sisteminin Llama motorusun. TÃ¼rkÃ§e cevap ver.' },
          { role: 'user', content: message }
        ],
        max_tokens: 4096
      })
    })
    const data = await response.json()
    return data.choices?.[0]?.message?.content || 'Together yanÄ±t veremedi.'
  } catch (error) {
    return `Together HatasÄ±: ${(error as Error).message}`
  }
}

// GitHub API Functions
async function githubListRepos(): Promise<string> {
  try {
    const response = await fetch('https://api.github.com/user/repos?per_page=10&sort=updated', {
      headers: { 'Authorization': `token ${process.env.GITHUB_TOKEN}` }
    })
    const repos = await response.json()
    if (!Array.isArray(repos)) return 'GitHub repo listesi alÄ±namadÄ±.'
    
    let result = 'ğŸ“ **GitHub RepolarÄ±nÄ±z:**\n\n'
    repos.forEach((repo: any, i: number) => {
      result += `${i + 1}. **${repo.name}**\n`
      result += `   â””â”€ ${repo.description || 'AÃ§Ä±klama yok'}\n`
      result += `   â””â”€ â­ ${repo.stargazers_count} | ğŸ´ ${repo.forks_count}\n\n`
    })
    return result
  } catch (error) {
    return `GitHub HatasÄ±: ${(error as Error).message}`
  }
}

async function githubReadFile(repo: string, path: string): Promise<string> {
  try {
    const response = await fetch(`https://api.github.com/repos/${repo}/contents/${path}`, {
      headers: { 'Authorization': `token ${process.env.GITHUB_TOKEN}` }
    })
    const data = await response.json()
    if (data.content) {
      const content = Buffer.from(data.content, 'base64').toString('utf-8')
      return `ğŸ“„ **${path}** iÃ§eriÄŸi:\n\n\`\`\`\n${content}\n\`\`\``
    }
    return 'Dosya okunamadÄ±.'
  } catch (error) {
    return `GitHub HatasÄ±: ${(error as Error).message}`
  }
}

// Vercel API Functions
async function vercelListProjects(): Promise<string> {
  try {
    const response = await fetch('https://api.vercel.com/v9/projects', {
      headers: { 'Authorization': `Bearer ${process.env.VERCEL_TOKEN}` }
    })
    const data = await response.json()
    if (!data.projects) return 'Vercel projeleri alÄ±namadÄ±.'
    
    let result = 'ğŸš€ **Vercel Projeleriniz:**\n\n'
    data.projects.forEach((project: any, i: number) => {
      result += `${i + 1}. **${project.name}**\n`
      result += `   â””â”€ Framework: ${project.framework || 'BelirtilmemiÅŸ'}\n`
      result += `   â””â”€ URL: ${project.targets?.production?.url || 'Yok'}\n\n`
    })
    return result
  } catch (error) {
    return `Vercel HatasÄ±: ${(error as Error).message}`
  }
}

// Supabase Query Function
async function supabaseQuery(sql: string): Promise<string> {
  try {
    // Not: Direkt SQL iÃ§in Supabase Management API veya Edge Function gerekir
    // Bu basit bir Ã¶rnek
    return `ğŸ“Š **SQL Sorgusu:**\n\`\`\`sql\n${sql}\n\`\`\`\n\nâš ï¸ Direkt SQL Ã§alÄ±ÅŸtÄ±rma iÃ§in Supabase Dashboard kullanÄ±n veya Edge Function oluÅŸturun.`
  } catch (error) {
    return `Supabase HatasÄ±: ${(error as Error).message}`
  }
}

// Railway API Functions
async function railwayStatus(): Promise<string> {
  try {
    // Railway GraphQL API kullanÄ±r
    return `ğŸš‚ **Railway Durumu:**\n\nâœ… yisa-s-app servisi: ONLINE\nâœ… Region: us-west2\nâœ… Son deploy: BaÅŸarÄ±lÄ±`
  } catch (error) {
    return `Railway HatasÄ±: ${(error as Error).message}`
  }
}

// Detect which model to use
function detectModel(message: string): AIModel {
  const lower = message.toLowerCase()
  if (lower.includes('gpt ile') || lower.includes('gpt kullan')) return 'gpt'
  if (lower.includes('gemini ile') || lower.includes('gemini kullan')) return 'gemini'
  if (lower.includes('together ile') || lower.includes('llama ile')) return 'together'
  return 'claude'
}

// Detect tool commands
function detectToolCommand(message: string): { tool: string; action: string; params: string[] } | null {
  const lower = message.toLowerCase()
  
  // GitHub commands
  if (lower.includes('github repo listele')) return { tool: 'github', action: 'listRepos', params: [] }
  if (lower.includes('github dosya oku')) {
    const match = message.match(/github dosya oku\s+(\S+)\s+(\S+)/i)
    if (match) return { tool: 'github', action: 'readFile', params: [match[1], match[2]] }
  }
  
  // Vercel commands
  if (lower.includes('vercel proje') && lower.includes('listele')) return { tool: 'vercel', action: 'listProjects', params: [] }
  
  // Supabase commands
  if (lower.includes('supabase sorgu')) {
    const match = message.match(/supabase sorgu(?:\s+Ã§alÄ±ÅŸtÄ±r)?\s+(.+)/i)
    if (match) return { tool: 'supabase', action: 'query', params: [match[1]] }
  }
  
  // Railway commands
  if (lower.includes('railway') && (lower.includes('durum') || lower.includes('status'))) {
    return { tool: 'railway', action: 'status', params: [] }
  }
  
  return null
}

// Execute tool command
async function executeToolCommand(command: { tool: string; action: string; params: string[] }): Promise<string> {
  switch (command.tool) {
    case 'github':
      if (command.action === 'listRepos') return await githubListRepos()
      if (command.action === 'readFile') return await githubReadFile(command.params[0], command.params[1])
      break
    case 'vercel':
      if (command.action === 'listProjects') return await vercelListProjects()
      break
    case 'supabase':
      if (command.action === 'query') return await supabaseQuery(command.params[0])
      break
    case 'railway':
      if (command.action === 'status') return await railwayStatus()
      break
  }
  return 'Komut Ã§alÄ±ÅŸtÄ±rÄ±lamadÄ±.'
}

export async function POST(request: NextRequest) {
  try {
    const { message, hasFile, fileType, fileName, fileContent } = await request.json()
    
    if (!message) {
      return NextResponse.json({ error: 'Mesaj gerekli' }, { status: 400 })
    }

    // Check for tool commands first
    const toolCommand = detectToolCommand(message)
    if (toolCommand) {
      const toolResult = await executeToolCommand(toolCommand)
      return NextResponse.json({ 
        message: toolResult,
        model: toolCommand.tool,
        status: 'tool_executed'
      })
    }

    // Detect which AI model to use
    const selectedModel = detectModel(message)
    let responseText = ''
    
    // Prepare message with file context if present
    let enhancedMessage = message
    if (hasFile && fileName) {
      enhancedMessage = `[DOSYA YÃœKLEME]
Dosya AdÄ±: ${fileName}
Dosya Tipi: ${fileType || 'bilinmiyor'}
${fileContent ? `\nDosya Ä°Ã§eriÄŸi:\n${fileContent}\n` : ''}
KullanÄ±cÄ± MesajÄ±: ${message}

Patron bu dosyayÄ± yÃ¼kledi. Ä°Ã§eriÄŸi analiz et ve istenen iÅŸlemi yap.`
    }

    // Call the appropriate AI model
    switch (selectedModel) {
      case 'gpt':
        responseText = await callGPT(enhancedMessage)
        break
      case 'gemini':
        responseText = await callGemini(enhancedMessage)
        break
      case 'together':
        responseText = await callTogether(enhancedMessage)
        break
      default:
        // Claude (default)
        const response = await anthropic.messages.create({
          model: 'claude-sonnet-4-20250514',
          max_tokens: 4096,
          system: SYSTEM_PROMPT,
          messages: [{ role: 'user', content: enhancedMessage }],
        })
        const content = response.content[0]
        responseText = content.type === 'text' ? content.text : ''
    }

    return NextResponse.json({ 
      message: responseText,
      model: selectedModel,
      status: 'patron_mode_active'
    })

  } catch (error) {
    console.error('Chat API error:', error)
    return NextResponse.json({ 
      message: 'Teknik sorun var Patron. Hata detayÄ±: ' + (error as Error).message 
    }, { status: 500 })
  }
}
